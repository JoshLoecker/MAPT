"""
I don't want to copy and paste the same thing through 18 files.
This script may be of use for later in the life of the pipeline

This script will take the output from /usr/bin/time -v [commands] and parse it into a simple csv file
We are going to take everything after the line `Command being timed: "` (including the trailing double quotes)
"""
from pprint import pprint
import pathlib
import pandas as pd
import os
import xlsxwriter
import csv


def parser(file_input: [pathlib.Path, str]):
    """
    This function will parse the file input to create a dictionary containing the statistics output at the end of the file create by /usr/bin/time -v [command]
    :param file_input: The file generated by /usr/bin/time -v [command]
    :return: A dictionary containing the key/value pairs from this command
    """
    # Simple exception handling
    try:
        with open(file_input, "r") as input_stream:
            file_lines = input_stream.readlines()

            # find the starting line
            for i, line in enumerate(file_lines):
                if 'Command being timed: "' in line:
                    data_start = i

        # All statistics are in this variable
        # Remove newline and tabs on either end of lines
        statistics = file_lines[data_start:]
        statistics = [line.strip() for line in statistics]

        # make a dictionary with key/value pairs
        data_dictionary = {}

        # get number of fast5 files used
        fast5_count = -1
        for value in range(1, 7):
            fast5_string = str(value) + "_fast5"
            if fast5_string in file_input:
                fast5_count = value
        data_dictionary["fast5_count"] = fast5_count

        for line in statistics:
            # lines are separated by `: `, so we can use this as our delimiter
            split_line = line.split(": ")
            key = split_line[0]
            value = split_line[1]
            data_dictionary[key] = value

        return data_dictionary
    except FileNotFoundError:
        print("File not found. Please check your path and try again.")
        print(f"File path: {file_input}")
        exit(1)


def return_database_name(file_path):
    if "silva" in file_path:
        return "silva"
    elif "zymo_modified" in file_path:
        return "zymo_modified"
    elif "zymo" in file_path:
        return "zymo"


def csv_writer(data: dict, database_name, header=True):
    """
    Take data input and write it to a new row in the Profiling Statistics file
    :return:
    """
    data_frame = pd.DataFrame([data], columns=data.keys())
    if database_name == "silva":
        data_frame.to_csv("./profiling/silva_profile.csv", index=False, mode="a", header=header)
    elif database_name == "zymo_modified":
        data_frame.to_csv("./profiling/zymo_modified_profile.csv", index=False, mode="a", header=header)
    elif database_name == "zymo":
        data_frame.to_csv("./profiling/zymo_profile.csv", index=False, mode="a", header=header)


def csv_converter():
    """
    This code is from the following source
    https://stackoverflow.com/a/17684679/13885200
    :return:
    """
    for file in os.listdir("./profiling"):
        if ".csv" in file:
            file_path = os.path.join("./profiling", file)
            workbook = xlsxwriter.Workbook(file_path[:-4] + ".xlsx", {"strings_to_numbers": True})
            worksheet = workbook.add_worksheet()
            with open(file_path, "rt") as input_stream:
                reader = csv.reader(input_stream)
                for r, row in enumerate(reader):
                    for c, column in enumerate(row):
                        if column.isdigit():
                            worksheet.write(r, c, int(column))
                        else:
                            worksheet.write(r, c, column)

            workbook.close()
            os.remove(file_path)


if __name__ == '__main__':
    silva_paths = []
    zymo_paths = []
    modified_zymo_paths = []
    for root, dirs, files in os.walk("./stress_test"):
        for file in files:
            if "output" in file:
                if "silva" in root:
                    silva_paths.append(os.path.join(root, file))
                elif "zymo_modified" in root:
                    modified_zymo_paths.append(os.path.join(root, file))
                elif "zymo" in root:
                    zymo_paths.append(os.path.join(root, file))

    # silva
    for i, path in enumerate(silva_paths):
        statistics_data = parser(path)
        database_name = return_database_name(path)
        # write headers on first pass
        if i == 0:
            csv_writer(statistics_data, database_name, header=True)
        else:
            csv_writer(statistics_data, database_name, header=False)

    # modified_zymo
    for i, path in enumerate(modified_zymo_paths):
        statistics_data = parser(path)
        database_name = return_database_name(path)
        # write headers on first pass
        if i == 0:
            csv_writer(statistics_data, database_name, header=True)
        else:
            csv_writer(statistics_data, database_name, header=False)

    # zymo
    for i, path in enumerate(zymo_paths):
        statistics_data = parser(path)
        database_name = return_database_name(path)
        # write headers on first pass
        if i == 0:
            csv_writer(statistics_data, database_name, header=True)
        else:
            csv_writer(statistics_data, database_name, header=False)

    csv_converter()
